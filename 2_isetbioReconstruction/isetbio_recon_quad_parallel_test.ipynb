{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba869530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup and load libraries\n",
    "import cupy as cp, numpy as np\n",
    "import main, torch, scipy.io, h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from inverse.bayes import *\n",
    "from inverse.solver import RenderMatrix, linear_inverse\n",
    "from utils.dataset import DataSet, gamma_correct\n",
    "from utils.sampling import forward_matrix\n",
    "from models.denoiser import Denoiser\n",
    "from tqdm.notebook import tqdm\n",
    "import os, cv2\n",
    "from collections import Counter\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import functools\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d9655b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(imageSetName, allCats, makeGrayscale, target_luminance, target_contrast, imOrig, imBorder):\n",
    "    # Normalize the luminance and root mean square contrast of images across all categories and redefine allCats as the new normalized image directories\n",
    "    new_allCats = []\n",
    "    for cc in allCats:\n",
    "        norm_cat = cc + '_norm'\n",
    "        new_dir = f'../stimulusSets/{imageSetName}_norm/{norm_cat}/'\n",
    "        if not os.path.exists(new_dir):\n",
    "            os.makedirs(new_dir)\n",
    "        allImgs = os.listdir(f'../stimulusSets/{imageSetName}/{cc}/')\n",
    "        allImgs = [img for img in allImgs if not img.startswith('.') and (img.endswith('.jpg') or img.endswith('.bmp') or img.endswith('.png'))]\n",
    "        for ii in allImgs:\n",
    "            img = cv2.imread(f'../stimulusSets/{imageSetName}/{cc}/{ii}')\n",
    "            if makeGrayscale:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            img = cv2.resize(img, (imOrig, imOrig))\n",
    "            unique_elements, counts = np.unique(img, return_counts=True)\n",
    "            most_frequent_index = np.argmax(counts)\n",
    "            borderVal = int(unique_elements[most_frequent_index])\n",
    "            replicate = cv2.copyMakeBorder(img, imBorder, imBorder, imBorder, imBorder, borderType=cv2.BORDER_CONSTANT, value=borderVal)\n",
    "            replicate = replicate / 255.0\n",
    "            replicate = replicate.astype(np.float32)\n",
    "\n",
    "            # Normalize luminance and contrast\n",
    "            mean_luminance = np.mean(replicate)\n",
    "            std_contrast = np.std(replicate)\n",
    "            normalized_img = (replicate - mean_luminance) / (std_contrast + 1e-8) * target_contrast + target_luminance\n",
    "            normalized_img = np.clip(normalized_img, 0, 1)\n",
    "\n",
    "            cv2.imwrite(f'{new_dir}{ii}', np.uint8(normalized_img*255))\n",
    "        new_allCats.append(norm_cat)\n",
    "    return new_allCats\n",
    "\n",
    "def process_block(args):\n",
    "    \"\"\"Process a single block - this function will be called in parallel\"\"\"\n",
    "    row_idx, col_idx, species, sceneFOVdegs, imageSetName, mosaicSize, imSize, blockLen, imBorder, blockSize, imOrig, makeGrayscale, target_luminance, target_contrast, norm_img = args\n",
    "    \n",
    "    # Calculate column values\n",
    "    if col_idx == 1:\n",
    "        col_val = np.arange(1,np.ceil(col_idx*blockLen+imBorder*2)+1)\n",
    "    elif col_idx==nBlock:\n",
    "        col_val = np.arange(np.ceil((col_idx-1)*blockLen), imSize+1)\n",
    "    else:\n",
    "        col_val = np.arange((col_idx-1)*blockLen,col_idx*blockLen+imBorder*2)\n",
    "\n",
    "    # Calculate row values\n",
    "    if row_idx == 1:\n",
    "        row_val = np.arange(1,np.ceil(row_idx*blockLen+imBorder*2)+1)\n",
    "    elif row_idx==nBlock:\n",
    "        row_val = np.arange(np.ceil((row_idx-1)*blockLen), imSize+1)\n",
    "    else:\n",
    "        row_val = np.arange((row_idx-1)*blockLen,row_idx*blockLen+imBorder*2)\n",
    "\n",
    "    eccY = ((np.mean(col_val)-(imSize/2))*mosaicSize/2)/(imSize/2)\n",
    "    eccX = ((np.mean(row_val)-(imSize/2))*mosaicSize/2)/(imSize/2)\n",
    "\n",
    "    FOV_val = str(sceneFOVdegs)\n",
    "    eccX_val = str(np.round(eccX,2))\n",
    "    eccY_val = str(np.round(eccY,2))\n",
    "\n",
    "    if sceneFOVdegs <= 2:\n",
    "        lbda = 1e-3\n",
    "    elif sceneFOVdegs <= 5 and sceneFOVdegs > 2:\n",
    "        lbda = 1e-2\n",
    "    elif sceneFOVdegs > 5:\n",
    "        lbda = 1e-1\n",
    "\n",
    "    file_path = f'/mnt/DataDrive2/treeshrew/data_raw/treeshrew_isetbio/renderMatrices/{species}_blocked/render_{FOV_val}_Xecc{eccX_val}_Yecc{eccY_val}_disptest.mat'\n",
    "\n",
    "    # load denoiser\n",
    "    main.args.model_path = './assets/conv3_ln.pt'\n",
    "    model = Denoiser(main.args)\n",
    "    model.load_state_dict(torch.load(main.args.model_path))\n",
    "    model = model.eval()\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Processing block ({row_idx}, {col_idx}) on device: {device}\")\n",
    "\n",
    "    data = h5py.File(file_path, 'r')\n",
    "    render_test = np.array(data['renderMtx']).astype(np.float32)\n",
    "    mtx = torch.tensor(render_test.astype(np.float32).T)\n",
    "\n",
    "    # have sparse prior file\n",
    "    prior = scipy.io.loadmat('./assets/sparsePrior.mat')\n",
    "    basis = np.linalg.inv(prior['regBasis'])\n",
    "    sparse = SparseEstimator(device, render_test.T, basis, prior['mu'].T, lbda=lbda)\n",
    "\n",
    "    # Initialize number of categories based on folders in konkle_imgs\n",
    "    allCats = os.listdir('../stimulusSets/'+imageSetName+'/')\n",
    "    allCats = [cat for cat in allCats if not cat.startswith('.')]\n",
    "\n",
    "    if norm_img:\n",
    "        allCats = normalize_image(imageSetName, allCats, makeGrayscale, target_luminance, target_contrast, imOrig, imBorder)\n",
    "        imageSetName = imageSetName + '_norm'\n",
    "\n",
    "    nCats = len(allCats)\n",
    "\n",
    "    for idx1,cc in enumerate(allCats):\n",
    "        print(f'Block ({row_idx}, {col_idx}) - Category: {cc}')\n",
    "        allImgs = os.listdir('../stimulusSets/'+imageSetName+'/'+cc+'/')\n",
    "        # exclude images that start with '.'\n",
    "        allImgs = [img for img in allImgs if not img.startswith('.') and (img.endswith('.jpg') or img.endswith('.bmp') or img.endswith('.png'))]\n",
    "        allImgs = allImgs\n",
    "        nImgs = len(allImgs)\n",
    "\n",
    "        img_tor = torch.zeros((nImgs,blockSize[2],blockSize[0],blockSize[1]))\n",
    "\n",
    "        for idx2,ii in enumerate(allImgs):\n",
    "            img = cv2.imread('../stimulusSets/'+imageSetName+'/' + cc + '/' + ii)\n",
    "\n",
    "            if makeGrayscale:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            img = cv2.resize(img, (imOrig, imOrig))\n",
    "\n",
    "            unique_elements, counts = np.unique(img, return_counts=True)\n",
    "            most_frequent_index = np.argmax(counts)\n",
    "            borderVal = int(unique_elements[most_frequent_index])\n",
    "            replicate = cv2.copyMakeBorder(img, imBorder, imBorder, imBorder, imBorder, borderType=cv2.BORDER_CONSTANT, value=borderVal)\n",
    "            replicate = replicate / 255.0\n",
    "\n",
    "            replicate = replicate.astype(np.float32)\n",
    "            crop_img = replicate[row_val.astype(int)-1, :][:, col_val.astype(int)-1]\n",
    "\n",
    "            if np.shape(crop_img)[0] - blockSize[0] == 1:\n",
    "                crop_img = crop_img[:int(blockSize[0]), :]\n",
    "            if np.shape(crop_img)[1] - blockSize[1] == 1:\n",
    "                crop_img = crop_img[:, :int(blockSize[1])]\n",
    "\n",
    "            img_torch = torch.tensor(crop_img.astype(np.float32)).to(device)\n",
    "            img_torch = img_torch.unsqueeze(0).repeat(3, 1, 1)  # Add channel dimension and repeat to match 3 channels\n",
    "\n",
    "            img_tor[idx2, :, :, :] = img_torch\n",
    "\n",
    "        msmt = BayesEstimator.measure(mtx, img_tor)\n",
    "        im_size = tuple([*img_tor.shape])\n",
    "\n",
    "        # run reconstructions, can check whether objective converges & maybe change n_iter\n",
    "        recon = sparse.recon(msmt.to(device), im_size, n_iter=num_it, print_loss=False)[0]\n",
    "\n",
    "        recon = recon.permute([0, 2, 3, 1]).cpu().numpy()\n",
    "\n",
    "        for idx in range(recon.shape[0]):\n",
    "            temp = gamma_correct(recon[idx])\n",
    "\n",
    "            if not os.path.exists(f'../stimulusSets/isettreeshrew/{species}_{FOV_val}/{imageSetName}_quad/{cc}/Xecc{eccX_val}_Yecc{eccY_val}'):\n",
    "                os.makedirs(f'../stimulusSets/isettreeshrew/{species}_{FOV_val}/{imageSetName}_quad/{cc}/Xecc{eccX_val}_Yecc{eccY_val}')\n",
    "            cv2.imwrite(f'../stimulusSets/isettreeshrew/{species}_{FOV_val}/{imageSetName}_quad/{cc}/Xecc{eccX_val}_Yecc{eccY_val}/{allImgs[idx]}',np.uint8(temp*255))\n",
    "    \n",
    "    return f\"Block ({row_idx}, {col_idx}) completed\"\n",
    "\n",
    "def run_parallel_threads():\n",
    "    # Create list of arguments for each block\n",
    "    block_args = []\n",
    "    for row_idx in range(1, nBlock+1):\n",
    "        for col_idx in range(1, nBlock+1):\n",
    "            args = (row_idx, col_idx, species, sceneFOVdegs, imageSetName, mosaicSize, imSize, blockLen, imBorder, blockSize, imOrig, makeGrayscale, target_luminance, target_contrast, norm_img)\n",
    "            block_args.append(args)\n",
    "    \n",
    "    # Use ThreadPoolExecutor (better for GPU-bound tasks)\n",
    "    n_threads = min(4, len(block_args))  # Limit threads to avoid GPU memory issues\n",
    "    print(f\"Using {n_threads} threads for {len(block_args)} blocks\")\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=n_threads) as executor:\n",
    "        future_to_block = {executor.submit(process_block, args): args for args in block_args}\n",
    "        \n",
    "        for future in as_completed(future_to_block):\n",
    "            args = future_to_block[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                print(result)\n",
    "            except Exception as exc:\n",
    "                print(f'Block {args[0:2]} generated an exception: {exc}')\n",
    "\n",
    "def merge_block_images():\n",
    "    # Initialize number of categories based on folders in konkle_imgs\n",
    "    if norm_img:\n",
    "        imSetName = imageSetName + '_norm'\n",
    "        \n",
    "    allCats = os.listdir('../stimulusSets/'+imSetName+'_quad/')\n",
    "    allCats = [cat for cat in allCats if not cat.startswith('.')]\n",
    "\n",
    "    for idx1,cc in enumerate(allCats):\n",
    "\n",
    "        allImgs = os.listdir('../stimulusSets/'+imSetName+'_quad/'+cc+'/')\n",
    "        # exclude images that start with '.'\n",
    "        allImgs = [img for img in allImgs if not img.startswith('.') and (img.endswith('.jpg') or img.endswith('.bmp') or img.endswith('.png'))]\n",
    "        nImgs = len(allImgs)\n",
    "\n",
    "        for idx2,ii in enumerate(allImgs):\n",
    "            init_img = np.zeros((imOrig, imOrig, 3), dtype=np.float32)\n",
    "\n",
    "            for row_idx in range(1, nBlock+1):\n",
    "                for col_idx in range(1, nBlock+1):\n",
    "\n",
    "                    if col_idx == 1:\n",
    "                        col_val = np.arange(1,np.ceil(col_idx*blockLen+imBorder*2)+1)\n",
    "                    elif col_idx==nBlock:\n",
    "                        col_val = np.arange(np.ceil((col_idx-1)*blockLen), imSize+1)\n",
    "                    else:\n",
    "                        col_val = np.arange((col_idx-1)*blockLen,col_idx*blockLen+imBorder*2)\n",
    "\n",
    "                    if row_idx == 1:\n",
    "                        row_val = np.arange(1,np.ceil(row_idx*blockLen+imBorder*2)+1)\n",
    "                    elif row_idx==nBlock:\n",
    "                        row_val = np.arange(np.ceil((row_idx-1)*blockLen), imSize+1)\n",
    "                    else:\n",
    "                        row_val = np.arange((row_idx-1)*blockLen,row_idx*blockLen+imBorder*2)\n",
    "\n",
    "                    col_block = np.arange((col_idx-1)*blockLen, col_idx*blockLen).astype(int)\n",
    "                    row_block = np.arange((row_idx-1)*blockLen, row_idx*blockLen).astype(int)\n",
    "\n",
    "                    eccY = ((np.mean(col_val)-(imSize/2))*mosaicSize/2)/(imSize/2)\n",
    "                    eccX = ((np.mean(row_val)-(imSize/2))*mosaicSize/2)/(imSize/2)\n",
    "                    FOV_val = str(sceneFOVdegs)\n",
    "                    Xstr = str(eccX)\n",
    "                    Ystr = str(eccY)\n",
    "\n",
    "                    eccX_val = str(np.round(eccX,2))\n",
    "                    eccY_val = str(np.round(eccY,2))\n",
    "\n",
    "                    file_path = f'../stimulusSets/isettreeshrew/{species}_{FOV_val}/{imSetName}_quad/{cc}/Xecc{eccX_val}_Yecc{eccY_val}/{allImgs[idx2]}'\n",
    "\n",
    "                    img = cv2.imread(file_path)\n",
    "                    img_size = img.shape[0]\n",
    "\n",
    "                    img_crop = img[imBorder:img_size-imBorder, imBorder:img_size-imBorder, :]\n",
    "\n",
    "                    init_img[np.ix_(row_block, col_block)] = img_crop\n",
    "\n",
    "            # plt.figure(figsize=(3, 3))\n",
    "            # plt.imshow(init_img/255.0)\n",
    "            # plt.show()\n",
    "\n",
    "            if not os.path.exists(f'../stimulusSets/isettreeshrew/{species}_{FOV_val}/{imSetName}_quad/{cc}/merged'):\n",
    "                os.makedirs(f'../stimulusSets/isettreeshrew/{species}_{FOV_val}/{imSetName}_quad/{cc}/merged')\n",
    "            cv2.imwrite(f'../stimulusSets/isettreeshrew/{species}_{FOV_val}/{imSetName}_quad/{cc}/merged/{allImgs[idx2]}',np.uint8(init_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18759876",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'imageSetName' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 36\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Run the parallelized version\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     33\u001b[0m     \n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# ThreadPoolExecutor (better for GPU-bound tasks)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# run_parallel_threads()\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     merge_block_images()\n",
      "Cell \u001b[0;32mIn[16], line 176\u001b[0m, in \u001b[0;36mmerge_block_images\u001b[0;34m()\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge_block_images\u001b[39m():\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# Initialize number of categories based on folders in konkle_imgs\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m norm_img:\n\u001b[0;32m--> 176\u001b[0m         imageSetName \u001b[38;5;241m=\u001b[39m imageSetName \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_norm\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    178\u001b[0m     allCats \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../stimulusSets/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mimageSetName\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_quad/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    179\u001b[0m     allCats \u001b[38;5;241m=\u001b[39m [cat \u001b[38;5;28;01mfor\u001b[39;00m cat \u001b[38;5;129;01min\u001b[39;00m allCats \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cat\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'imageSetName' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "torch.cuda.set_device(1)\n",
    "species = 'treeshrew'\n",
    "sceneFOVdegs = 1.25\n",
    "imageSetName = 'Kiani_ImageSet'\n",
    "sceneFOVscale = 1.2\n",
    "num_it = 4000\n",
    "\n",
    "makeGrayscale = True\n",
    "norm_img = True\n",
    "target_luminance = 0.5\n",
    "target_contrast = 0.1\n",
    "\n",
    "imOrig = 227\n",
    "imBorder = int((np.ceil(imOrig*sceneFOVscale) - imOrig)/2)\n",
    "imSize = np.ceil(imOrig + imBorder*2)\n",
    "\n",
    "borderSize = ((sceneFOVscale*sceneFOVdegs) - sceneFOVdegs)/2\n",
    "mosaicSize = sceneFOVdegs+borderSize*2\n",
    "\n",
    "if sceneFOVdegs < 1:\n",
    "    nBlock = 2\n",
    "elif sceneFOVdegs >= 1 and sceneFOVdegs < 5:\n",
    "    nBlock = 4\n",
    "elif sceneFOVdegs >=5:\n",
    "    nBlock = 6\n",
    "\n",
    "blockLen = imOrig/nBlock\n",
    "blockSize = [int(np.ceil(blockLen+imBorder*2)), int(np.ceil(blockLen+imBorder*2)), 3]\n",
    "\n",
    "# Run the parallelized version\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # ThreadPoolExecutor (better for GPU-bound tasks)\n",
    "    # run_parallel_threads()\n",
    "    merge_block_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c15586",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
